{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的\n",
    "機械学習分野の論文から有益な情報を引き出せるようにする  \n",
    "これまで扱ってきた領域の論文から新たな知識を得る  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 論文読解\n",
    "  \n",
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。  \n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99  \n",
    "\n",
    "https://arxiv.org/pdf/1506.01497.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) 物体検出の分野にはどういった手法が存在したか。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPPnet、Fast R-CNN   \n",
    ">Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.  \n",
    "-Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun  \n",
    "\n",
    "(Faster R-CNN Abstract )\n",
    "  \n",
    "  \n",
    "R- CNNs  \n",
    "\n",
    ">Recent advances in object detection are driven by the success of region proposal methods (e.g., [4]) and region-based convolutional neural networks (R- CNNs) [5].  \n",
    "-Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\n",
    "\n",
    "(Faster R-CNN 1 INTRODUCTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Fasterとあるが、どういった仕組みで高速化したのか。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み特徴量を下流の検出ネットワークと共有することによって、領域提案の段階の処理コストをほぼなくすことができる。  \n",
    "\n",
    "> By sharing convolutional features with the down-stream detection network, the region proposal step is nearly cost-free. Our method enables a unified, deep-learning-based object detec- tion system to run at near real-time frame rates. The learned RPN also improves region proposal quality and thus the overall object detection accuracy.  \n",
    "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\n",
    "\n",
    "\n",
    "(Faster R-CNN 5 CONCLUSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One-Stageの手法について  \n",
    " ・クラスを特定するパイプラインである\n",
    " >OverFeat is a one-stage, class-specific detection pipeline,    \n",
    " \n",
    "\n",
    "(Faster R-CNN 4.1 Experiments on PASCAL VOC)　\n",
    "    \n",
    "・スケールピラミッド（解像度の異なる同一画像の集合）上を一定のアスペクト比の窓をスライドさせることで領域的な特徴量を得る。一般的にそれらの特徴量で位置と物体の分類を同時に行う。\n",
    "> In OverFeat, the region-wise features come from a sliding window of one aspect ratio over a scale pyramid.These features are used to simultaneously determine the location and category of objects.     \n",
    " \n",
    "(Faster R-CNN 4.1 Experiments on PASCAL VOC)　\n",
    " \n",
    " Two-Stageの手法について  \n",
    "・クラスと関係なく推定する段階とクラスに応じた検出をする段階のカスケード構成になっている。  \n",
    ">ours is a two-stage cascade consisting of class-agnostic pro- posals and class-specific detections.     \n",
    "\n",
    "(Faster R-CNN 4.1 Experiments on PASCAL VOC)　\n",
    "  \n",
    "・RPNでは、特徴量は正方形 (3×3) ​の窓をスライドさせたものから生成し、また異なるスケールとアスペクト比のアンカーとの関連を推定する。\n",
    ">In RPN, the features are from square (3×3) sliding windows and predict proposals relative to anchors with different scales and aspect ratios.      \n",
    "\n",
    "(Faster R-CNN 4.1 Experiments on PASCAL VOC)　\n",
    "\n",
    "・第二段階では、領域の特徴量より信用度の高いボックスを代表として推定し、領域特徴量を最適にプールする。  \n",
    ">In the second stage of our cascade, the region-wise features are adaptively pooled [1], [2] from proposal boxes that more faith- fully cover the features of the regions. We believe these features lead to more accurate detections.    \n",
    "\n",
    "(Faster R-CNN 4.1 Experiments on PASCAL VOC)　\n",
    "  \n",
    "-Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPNは全畳み込み特徴量を検出ネットワークと共有することによって、領域提案のコストがほぼかからなくなる。RPNは完全畳み込みネットワークで、同時に物体の境界と物体らしさの評価値をそれぞれの位置で推定する。RPNはエンドトゥーエンドで学習されており、Fast R-CNNでの検出するために用いられる精度の高い物体領域予測を生成する。また、畳み込み特徴量を共有することによって、RPNとFast R-CNNを一つのネットワークに統合する。\n",
    "\n",
    "> In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with “attention” mechanisms, the RPN component tells the unified network where to look.\n",
    "\n",
    "(Faster R-CNN Abstract)　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みした特徴量マップと予測領域を入力として受け取る  \n",
    "提案された領域の中でmaxpoolingを行う  \n",
    "出力スケールは固定されていて、全てそのサイズにスケーリングする  \n",
    "  \n",
    "  \n",
    ">(iii) Non-approximate joint training. As discussed above, the bounding boxes predicted by RPN are also functions of the input. The RoI pooling layer [2] in Fast R-CNN accepts the convolutional features and also the predicted bounding boxes as input, so a theoretically valid backpropagation solver should also involve gradients w.r.t. the box coordinates. These gradients are ignored in the above approximate joint training. In a non-approximate joint training solution, we need an RoI pooling layer that is differentiable w.r.t. the box coordinates. This is a nontrivial problem and a solution can be given by an “RoI warping” layer as developed in [15], which is beyond the scope of this paper.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ">Table 8: Detection results of Faster R-CNN on PAS- CAL VOC 2007 test set using different settings of anchors. The network is VGG-16. The training data is VOC 2007 trainval. The default setting of using 3 scales and 3 aspect ratios (69.9%) is the same as that in Table 3.\n",
    "  \n",
    "Table 8  \n",
    "settings anchor scales spect ratios mAP  \n",
    "1 scale, 1 ratio 128^2 1:1 65.8  \n",
    "1 scale, 3 ratios 128^2 {2:1, 1:1, 1:2} 68.8  \n",
    "3 scales, 1 ratio {128^2,256^2,512^2} 1:1 69.8  \n",
    "3 scales, 3 ratios {128^2,256^2,512^2} {2:1, 1:1, 1:2} 69.9  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用したデータセット  \n",
    "PASCAL VOC 2007  \n",
    "PASCAL VOC 2012  \n",
    "Microsoft COCO object detection dataset  \n",
    "比較  \n",
    "Fast R-CNN mAP:35.9  \n",
    "Faster R-CNN mAP:42.7  \n",
    "先行研究に比べ高いmAPを得られている  \n",
    "また、計算速度も早い  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
